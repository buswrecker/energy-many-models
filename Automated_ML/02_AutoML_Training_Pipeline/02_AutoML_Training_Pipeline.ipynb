{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/manymodels/02_Training/02_Training_Pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline - Automated ML\n",
    "_**Training many models using Automated Machine Learning**_\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates how to train and register 50 models using Automated Machine Learning. We will utilize the [ParallelRunStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallel_run_step.parallelrunstep?view=azure-ml-py) to parallelize the process of training 50 models. For this notebook we are using the Energy Dataset to predict the solar production of each home in each suburb. For more information about the data refer to the Data Preparation Notebook.\n",
    "\n",
    "<span style=\"color:red\"><b>NOTE: There are limits on how many runs we can do in parallel per workspace, and we currently recommend to set the parallelism to maximum of 20 runs per experiment per workspace. If users want to have more parallelism and increase this limit they might encounter Too Many Requests errors (HTTP 429). </b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b> Please ensure you have the latest version of the SDK to ensure AutoML dependencies are consistent.</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade azureml-sdk[automl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also install the pipeline.steps package that is needed for parallel run step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade azureml-pipeline-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should have already:\n",
    "\n",
    "1. Created your AML Workspace using the [00_Setup_AML_Workspace notebook](../../00_Setup_AML_Workspace.ipynb)\n",
    "2. Run [01_Data_Preparation.ipynb](../../01_Data_Preparation.ipynb) to create the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Set up workspace, datastore, experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>33125c98-8730-4ada-8519-4282d89758eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>mme-test-sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>westus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Default datastore name</th>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            \n",
       "SDK version             1.14.0                              \n",
       "Subscription ID         33125c98-8730-4ada-8519-4282d89758eb\n",
       "Workspace               mme-test-sa                         \n",
       "Resource Group          sample                              \n",
       "Location                westus                              \n",
       "Default datastore name  energy                              "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "import pandas as pd\n",
    "\n",
    "# set up workspace\n",
    "ws= Workspace.from_config() \n",
    "\n",
    "# Take a look at Workspace\n",
    "ws.get_details()\n",
    "\n",
    "# set up datastores\n",
    "#dstore = ws.get_default_datastore()\n",
    "dstore = Datastore.get(ws, datastore_name='energy')\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Default datastore name'] = dstore.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: manymodels-training-pipeline\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, 'manymodels-training-pipeline')\n",
    "\n",
    "print('Experiment name: ' + experiment.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Call the registered filedataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 50 datasets and ParallelRunStep to build 50 time-series to predict the solar production of each home. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset represents a 1 years worth of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to register the datasets in the Workspace first. We did so in the [data preparation notebook](../../01_Data_Preparation.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "Energy50 = Dataset.get_by_name(ws, name='Energy50_train')\n",
    "Energy50_input = Energy50.as_named_input('train_50_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Build the training pipeline\n",
    "Now that the dataset, WorkSpace, and datastore are set up, we can put together a pipeline for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment  for ParallelRunStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Environment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment.environment?view=azure-ml-py) defines a collection of resources that we will need to run our pipelines. We configure a reproducible Python environment for our training script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helper import get_automl_environment\n",
    "from azureml.core import Environment\n",
    "train_env = get_automl_environment()\n",
    "\n",
    "##Register the environment \n",
    "train_env.register(workspace=ws)\n",
    "\n",
    "##If the Environment is registered; retrieve this here\n",
    "train_env = Environment.get(ws,\"many_models_environment_automl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a compute target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently ParallelRunConfig only supports AMLCompute. You can change to a different compute cluster if one fails.\n",
    "\n",
    "This is the compute target we will pass into our ParallelRunConfig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "Checking cluster status...\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"cpucluster\"\n",
    "\n",
    "\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "    found = True\n",
    "    print('Found existing compute target.')\n",
    "    compute = cts[amlcompute_cluster_name]\n",
    "    \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D13_V2',\n",
    "                                                           min_nodes=2,\n",
    "                                                           max_nodes=20)\n",
    "    # Create the cluster. It would be recommended to use GPU-clusters if you're using AutoML-DeepLearning models\n",
    "    compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    \n",
    "print('Checking cluster status...')\n",
    "# Can poll for a minimum number of nodes and for a specific timeout.\n",
    "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "compute.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "\n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "This dictionary defines the [AutoML settings](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py#parameters), for this forecasting task we add the name of the time column and the maximum forecast horizon.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|forecasting|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n",
    "|**blacklist_models**|Models in blacklist won't be used by AutoML. All supported models can be found at [here](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.constants.supportedmodels.forecasting?view=azure-ml-py).|\n",
    "|**iterations**|Number of models to train. This is optional but provides customer with greater control.|\n",
    "|**iteration_timeout_minutes**|Maximum amount of time in minutes that the model can train. This is optional and depends on the dataset. We ask customer to explore a bit to get approximate times for training the dataset. For OJ dataset we set it 20 minutes|\n",
    "|**experiment_timeout_hours**|Maximum amount of time in hours that the experiment can take before it terminates.|\n",
    "|**label_column_name**|The name of the label column.|\n",
    "|**n_cross_validations**|Number of cross validation splits. Rolling Origin Validation is used to split time-series in a temporally consistent way.|\n",
    "|**enable_early_stopping**|Flag to enable early termination if the score is not improving in the short term.|\n",
    "|**time_column_name**|The name of your time column.|\n",
    "|**max_horizon**|The number of periods out you would like to predict past your training data. Periods are inferred from your data.|\n",
    "|**grain_column_names**|The column names used to uniquely identify timeseries in data that has multiple rows with the same timestamp.|\n",
    "|**group_column_names**|The names of columns used to group your models. For timeseries, the groups must not split up individual time-series. That is, each group must contain one or more whole time-series.|\n",
    "|**drop_column_names**|The names of columns to drop for forecasting tasks.|\n",
    "|**track_child_runs**|Flag to disable tracking of child runs. Only best run (metrics and model) is tracked if the flag is set to False.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from scripts.helper import write_automl_settings_to_file\n",
    "\n",
    "automl_settings = {\n",
    "    \"task\" : 'forecasting',\n",
    "    \"primary_metric\" : 'normalized_root_mean_squared_error',\n",
    "    \"iteration_timeout_minutes\" : 5, # This needs to be changed based on the dataset. We ask customer to explore how long training is taking before settings this value\n",
    "    \"iterations\" : 5,\n",
    "    \"experiment_timeout_minutes\" : 60,\n",
    "    \"label_column_name\" : 'Solar',\n",
    "    \"n_cross_validations\" : 2,\n",
    "    \"verbosity\" : logging.INFO, \n",
    "    \"debug_log\": 'automl_oj_sales_debug.txt',\n",
    "    \"time_column_name\": 'EndDate',\n",
    "    \"max_horizon\" : 10,\n",
    "    \"max_cores_per_iteration\": 4, ##Depends on the VM Type\n",
    "    \"max_concurrent_iterations\": 10, ##Depends on the VM Type\n",
    "    \"enable_tf\": True,  ##Set to True if you're using GPU VMs - this will use Tensorflow/DL to forecast\n",
    "    \"group_column_names\": ['Suburb', 'Home'],\n",
    "    \"grain_column_names\": ['Suburb', 'Home'],\n",
    "    \"drop_column_names\": ['DeviceNumber','Generalusage'],\n",
    "    \"blacklist_models\": ['Average','Naive']\n",
    "}\n",
    "\n",
    "write_automl_settings_to_file(automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ParallelRunConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ParallelRunConfig](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallel_run_config.parallelrunconfig) is configuration for parallel run step. You will need to determine the number of workers and nodes appropriate for your use case. The process_count_per_node is based off the number of cores of the compute VM. The node_count will determine the number of master nodes to use, increasing the node count will speed up the training process.\n",
    "\n",
    "\n",
    "* <b>node_count</b>: The number of compute nodes to be used for running the user script. We recommend to start with 3 and increase the node_count if the training time is taking too long.\n",
    "\n",
    "* <b>process_count_per_node</b>: The number of processes per node.\n",
    "\n",
    "* <b>run_invocation_timeout</b>: The run() method invocation timeout in seconds. The timeout should be set to maximum training time of one AutoML run(with some buffer), by default it's 60 seconds.\n",
    "\n",
    "<span style=\"color:red\"><b>NOTE: There are limits on how many runs we can do in parallel per workspace, and we currently recommend to set the parallelism to maximum of 20 runs per experiment per workspace. If users want to have more parallelism and increase this limit they might encounter Too Many Requests errors (HTTP 429). </b></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helper import build_parallel_run_config\n",
    "\n",
    "# PLEASE MODIFY the following three settings based on your compute and experiment timeout.\n",
    "node_count=4\n",
    "process_count_per_node=5\n",
    "run_invocation_timeout=3700 # this timeout(in seconds) is inline with AutoML experiment timeout or (no of iterations * iteration timeout)\n",
    "\n",
    "parallel_run_config = build_parallel_run_config(train_env, compute, node_count, process_count_per_node, run_invocation_timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ParallelRunStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [ParallelRunStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallelrunstep?view=azure-ml-py) is the main step in our pipeline. First, we set up the output directory and define the Pipeline's output name. The datastore that stores the pipeline's output data is Workspace's default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "training_output_name = \"training_output\"\n",
    "\n",
    "output_dir = PipelineData(name=training_output_name, \n",
    "                          datastore=dstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the following parameters:\n",
    "\n",
    "* <b>name</b>: We set a name for our ParallelRunStep.\n",
    "\n",
    "* <b>parallel_run_config</b>: We then pass the previously defined ParallelRunConfig.\n",
    "\n",
    "* <b>allow_reuse</b>: Indicates whether the step should reuse previous results when re-run with the same settings. \n",
    "\n",
    "* <b>inputs</b>: We are going to use the registered FileDataset that we called earlier in the Notebook. _inputs_ points to a registered file dataset in AML studio that points to a path in the blob container. The number of files in that path determines the number of models will be trained in the ParallelRunStep. \n",
    "\n",
    "* <b>output</b>: The output directory we just defined. A PipelineData object that corresponds to the output directory.\n",
    "\n",
    "* <b>models</b>: Zero or more model names already registered in the Azure Machine Learning model registry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>Please upgrade azureml-pipeline-steps(>=1.6.0) if the following fails.</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import ParallelRunStep\n",
    "\n",
    "parallel_run_step = ParallelRunStep(\n",
    "    name=\"many-models-training\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    allow_reuse = False,\n",
    "    inputs=[Energy50_input], # train 10 models\n",
    "    #inputs=[filedst_all_models_inputs], # switch to this inputs if train all 11,973 models\n",
    "    output=output_dir,\n",
    "    #arguments=['--retrain_failed_models', 'True'], # Uncomment this if you want to retrain only failed models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Run the training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we submit our pipeline to run. The whole training pipeline takes about 1h 11m using a Standard_D13_V2 VM with our current ParallelRunConfig setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step many-models-training [66a369aa][887e0fbe-5bb2-47e1-bcf9-a153fd2cd7e8], (This step will run and generate new outputs)\n",
      "Using data reference train_50_models_0 for StepId [b3d4dc6d][8af75f2e-94ea-4912-92e8-6a50263a8ecd], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted PipelineRun e8b0f6e9-5716-49e5-8245-e4b8c75f2ea1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/manymodels-training-pipeline/runs/e8b0f6e9-5716-49e5-8245-e4b8c75f2ea1?wsid=/subscriptions/33125c98-8730-4ada-8519-4282d89758eb/resourcegroups/sample/workspaces/mme-test-sa\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "#from azureml.widgets import RunDetails\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=parallel_run_step)\n",
    "run = experiment.submit(pipeline)\n",
    "#RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the folowing command if you'd like to monitor the training process in jupyter notebook. It will stream logs live while training. \n",
    "\n",
    "**Note**: This command may not work for Notebook VM, however it should work on your local laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 83fc9301-7cce-4637-bf9e-445f4de4dd41\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/manymodels-training-pipeline/runs/83fc9301-7cce-4637-bf9e-445f4de4dd41?wsid=/subscriptions/33125c98-8730-4ada-8519-4282d89758eb/resourcegroups/sample/workspaces/mme-test-sa\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 63511730-a6f0-4a6e-984c-ed972840081f\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/manymodels-training-pipeline/runs/63511730-a6f0-4a6e-984c-ed972840081f?wsid=/subscriptions/33125c98-8730-4ada-8519-4282d89758eb/resourcegroups/sample/workspaces/mme-test-sa\n",
      "StepRun( many-models-training ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_0555844bd79b85553ca984d1883fc82dd82e538e0b5ee3605566724ba5136287_d.txt\n",
      "========================================================================================================================\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_bafd6ade1c94d3b2014fc6b378f62160\n",
      "8e097b52bfb8: Pulling fs layer\n",
      "a613a9b4553c: Pulling fs layer\n",
      "acc000f01536: Pulling fs layer\n",
      "73eef93b7466: Pulling fs layer\n",
      "d5a54c1fb97f: Pulling fs layer\n",
      "1536f6ca931b: Pulling fs layer\n",
      "d7b631d130cb: Pulling fs layer\n",
      "75ffe8dfb222: Pulling fs layer\n",
      "86b4bf2f8d5f: Pulling fs layer\n",
      "5335952fa8d3: Pulling fs layer\n",
      "96fa3cc6fe10: Pulling fs layer\n",
      "e428dd9daa94: Pulling fs layer\n",
      "483719f86357: Pulling fs layer\n",
      "f77e4b8c7b89: Pulling fs layer\n",
      "143248771014: Pulling fs layer\n",
      "45c83dda7fab: Pulling fs layer\n",
      "a94ac532b4ae: Pulling fs layer\n",
      "94e700a79754: Pulling fs layer\n",
      "1536f6ca931b: Waiting\n",
      "d7b631d130cb: Waiting\n",
      "75ffe8dfb222: Waiting\n",
      "86b4bf2f8d5f: Waiting\n",
      "73eef93b7466: Waiting\n",
      "d5a54c1fb97f: Waiting\n",
      "5335952fa8d3: Waiting\n",
      "96fa3cc6fe10: Waiting\n",
      "483719f86357: Waiting\n",
      "e428dd9daa94: Waiting\n",
      "f77e4b8c7b89: Waiting\n",
      "a94ac532b4ae: Waiting\n",
      "143248771014: Waiting\n",
      "45c83dda7fab: Waiting\n",
      "94e700a79754: Waiting\n",
      "acc000f01536: Verifying Checksum\n",
      "acc000f01536: Download complete\n",
      "a613a9b4553c: Verifying Checksum\n",
      "a613a9b4553c: Download complete\n",
      "73eef93b7466: Download complete\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_02704bc030c8a1508e60ed5c637a80cfc908e7a76c3711f7db6f24fcdbb84eac_d.txt\n",
      "========================================================================================================================\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_bafd6ade1c94d3b2014fc6b378f62160\n",
      "8e097b52bfb8: Pulling fs layer\n",
      "a613a9b4553c: Pulling fs layer\n",
      "acc000f01536: Pulling fs layer\n",
      "73eef93b7466: Pulling fs layer\n",
      "d5a54c1fb97f: Pulling fs layer\n",
      "1536f6ca931b: Pulling fs layer\n",
      "d7b631d130cb: Pulling fs layer\n",
      "75ffe8dfb222: Pulling fs layer\n",
      "86b4bf2f8d5f: Pulling fs layer\n",
      "5335952fa8d3: Pulling fs layer\n",
      "96fa3cc6fe10: Pulling fs layer\n",
      "e428dd9daa94: Pulling fs layer\n",
      "483719f86357: Pulling fs layer\n",
      "f77e4b8c7b89: Pulling fs layer\n",
      "d5a54c1fb97f: Waiting\n",
      "143248771014: Pulling fs layer\n",
      "45c83dda7fab: Pulling fs layer\n",
      "a94ac532b4ae: Pulling fs layer\n",
      "1536f6ca931b: Waiting\n",
      "94e700a79754: Pulling fs layer\n",
      "73eef93b7466: Waiting\n",
      "d7b631d130cb: Waiting\n",
      "75ffe8dfb222: Waiting\n",
      "5335952fa8d3: Waiting\n",
      "143248771014: Waiting\n",
      "86b4bf2f8d5f: Waiting\n",
      "96fa3cc6fe10: Waiting\n",
      "45c83dda7fab: Waiting\n",
      "e428dd9daa94: Waiting\n",
      "a94ac532b4ae: Waiting\n",
      "483719f86357: Waiting\n",
      "f77e4b8c7b89: Waiting\n",
      "94e700a79754: Waiting\n",
      "acc000f01536: Download complete\n",
      "a613a9b4553c: Download complete\n",
      "73eef93b7466: Download complete\n",
      "8e097b52bfb8: Verifying Checksum\n",
      "8e097b52bfb8: Download complete\n",
      "1536f6ca931b: Verifying Checksum\n",
      "1536f6ca931b: Download complete\n",
      "d7b631d130cb: Verifying Checksum\n",
      "d7b631d130cb: Download complete\n",
      "d5a54c1fb97f: Verifying Checksum\n",
      "d5a54c1fb97f: Download complete\n",
      "5335952fa8d3: Verifying Checksum\n",
      "5335952fa8d3: Download complete\n",
      "75ffe8dfb222: Verifying Checksum\n",
      "75ffe8dfb222: Download complete\n",
      "96fa3cc6fe10: Verifying Checksum\n",
      "96fa3cc6fe10: Download complete\n",
      "e428dd9daa94: Download complete\n",
      "f77e4b8c7b89: Download complete\n",
      "483719f86357: Download complete\n",
      "45c83dda7fab: Verifying Checksum\n",
      "45c83dda7fab: Download complete\n",
      "86b4bf2f8d5f: Verifying Checksum\n",
      "86b4bf2f8d5f: Download complete\n",
      "143248771014: Verifying Checksum\n",
      "143248771014: Download complete\n",
      "94e700a79754: Verifying Checksum\n",
      "94e700a79754: Download complete\n",
      "8e097b52bfb8: Pull complete\n",
      "a613a9b4553c: Pull complete\n",
      "acc000f01536: Pull complete\n",
      "73eef93b7466: Pull complete\n",
      "d5a54c1fb97f: Pull complete\n",
      "1536f6ca931b: Pull complete\n",
      "a94ac532b4ae: Verifying Checksum\n",
      "a94ac532b4ae: Download complete\n",
      "d7b631d130cb: Pull complete\n",
      "75ffe8dfb222: Pull complete\n",
      "86b4bf2f8d5f: Pull complete\n",
      "5335952fa8d3: Pull complete\n",
      "96fa3cc6fe10: Pull complete\n",
      "e428dd9daa94: Pull complete\n",
      "483719f86357: Pull complete\n",
      "f77e4b8c7b89: Pull complete\n",
      "143248771014: Pull complete\n",
      "45c83dda7fab: Pull complete\n",
      "a94ac532b4ae: Pull complete\n",
      "94e700a79754: Pull complete\n",
      "Digest: sha256:412049530c23c09df3929cb92f44d90ac4c8c8f57a8276c836a274d619e1d137\n",
      "Status: Downloaded newer image for f815d72d4c7546ca97ce30de1cd4159b.azurecr.io/azureml/azureml_bafd6ade1c94d3b2014fc6b378f62160:latest\n",
      "11abf33c0bcc4a69cf90379fa7f953fabe8b55b9452a5553d75d17bbe944c849\n",
      "2020/09/30 00:24:58 setuptask.go:379: Instrumentation Key Is Empty Skipping App Insight Logger\n",
      "2020/09/30 00:24:58 logger.go:297: Version: 3.0.01366.0003 Branch: hotfixWithTurnoffazsecpack Commit: 8560948\n",
      "2020/09/30 00:24:58 utils.go:321: /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/09/30 00:24:58 logger.go:297: sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_097732faf160663540004ec4a908707d/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_097732faf160663540004ec4a908707d/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "2020/09/30 00:24:58 appinsightlogger.go:46: Logger is Nil nothing to close\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_02704bc030c8a1508e60ed5c637a80cfc908e7a76c3711f7db6f24fcdbb84eac_d.txt\n",
      "===============================================================================================================\n",
      "[2020-09-30T00:24:59.289078] Entering job preparation.\n",
      "[2020-09-30T00:24:59.492512] TimeoutHandler __init__\n",
      "[2020-09-30T00:24:59.492545] TimeoutHandler __enter__\n",
      "[2020-09-30T00:24:59.493744] Starting job preparation.\n",
      "[2020-09-30T00:24:59.493771] Extracting the control code.\n",
      "[2020-09-30T00:24:59.509984] Waiting for master node to finish fetching and extracting the control code. Will check again in 1 seconds.\n",
      "[2020-09-30T00:25:00.520870] Waiting for master node to finish fetching and extracting the control code. Will check again in 3 seconds.\n",
      "[2020-09-30T00:25:03.529710] Waiting for master node to finish fetching and extracting the control code. Will check again in 5 seconds.\n",
      "[2020-09-30T00:25:08.539661] Waiting for master node to finish fetching and extracting the control code. Will check again in 7 seconds.\n",
      "[2020-09-30T00:25:15.550432] Finished fetching and extracting the control code.\n",
      "[2020-09-30T00:25:15.550551] downloadDataStore - Download from datastores if requested.\n",
      "[2020-09-30T00:25:15.605877] Entering context manager injector.\n",
      "Acquired lockfile /tmp/63511730-a6f0-4a6e-984c-ed972840081f-datastore.lock to downloading input data references\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 88\n",
      "[2020-09-30T00:25:18.258396] downloadDataStore completed\n",
      "[2020-09-30T00:25:18.258450] Not a master node. Skipping rest of the context managers.\n",
      "[2020-09-30T00:25:18.258489] TimeoutHandler __exit__\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/09/30 00:25:23 logger.go:297: Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2020/09/30 00:25:23 logger.go:297: Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "[2020-09-30T00:25:25.264325] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.14.0', '--scoring_module_name', 'train_automl.py', '--mini_batch_size', '1', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '3700', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/mme-test-sa/azureml/63511730-a6f0-4a6e-984c-ed972840081f/mounts/energy/azureml/63511730-a6f0-4a6e-984c-ed972840081f/training_output', '--process_count_per_node', '5', '--input_fds_0', 'train_50_models', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/mme-test-sa/azureml/63511730-a6f0-4a6e-984c-ed972840081f/mounts/energy/energy_train'])\n",
      "Initialize DatasetContextManager.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 173\n",
      "Set Dataset train_50_models's target path to /mnt/batch/tasks/shared/LS_root/jobs/mme-test-sa/azureml/63511730-a6f0-4a6e-984c-ed972840081f/mounts/workspaceblobstore/azureml/63511730-a6f0-4a6e-984c-ed972840081f/2d2d30ae-452a-4a72-aa96-932540db3a82\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.14.0.post1 azureml-dataprep==2.1.6. Session id: e66cda5a-2582-4994-96ea-b6f3f6c4f20c. Run id: 63511730-a6f0-4a6e-984c-ed972840081f.\n",
      "Processing 'train_50_models'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('energy', 'energy_train')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"e5c6fe9c-385c-4490-a8a4-c5495743bdc3\",\n",
      "    \"name\": \"energy50_train\",\n",
      "    \"version\": 2,\n",
      "    \"workspace\": \"Workspace.create(name='mme-test-sa', subscription_id='33125c98-8730-4ada-8519-4282d89758eb', resource_group='sample')\"\n",
      "  }\n",
      "}\n",
      "Mounted train_50_models to /mnt/batch/tasks/shared/LS_root/jobs/mme-test-sa/azureml/63511730-a6f0-4a6e-984c-ed972840081f/mounts/energy/energy_train\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Entering Run History Context Manager.\n",
      "Current directory:  /mnt/batch/tasks/shared/LS_root/jobs/mme-test-sa/azureml/63511730-a6f0-4a6e-984c-ed972840081f/mounts/workspaceblobstore/azureml/63511730-a6f0-4a6e-984c-ed972840081f\n",
      "Preparing to call script [ driver/amlbi_main.py ] with arguments: ['--client_sdk_version', '1.14.0', '--scoring_module_name', 'train_automl.py', '--mini_batch_size', '1', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '3700', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/mme-test-sa/azureml/63511730-a6f0-4a6e-984c-ed972840081f/mounts/energy/azureml/63511730-a6f0-4a6e-984c-ed972840081f/training_output', '--process_count_per_node', '5', '--input_fds_0', 'train_50_models', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/mme-test-sa/azureml/63511730-a6f0-4a6e-984c-ed972840081f/mounts/energy/energy_train']\n",
      "After variable expansion, calling script [ driver/amlbi_main.py ] with arguments: ['--client_sdk_version', '1.14.0', '--scoring_module_name', 'train_automl.py', '--mini_batch_size', '1', '--error_threshold', '-1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '3700', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/mme-test-sa/azureml/63511730-a6f0-4a6e-984c-ed972840081f/mounts/energy/azureml/63511730-a6f0-4a6e-984c-ed972840081f/training_output', '--process_count_per_node', '5', '--input_fds_0', 'train_50_models', '--input1', '/mnt/batch/tasks/shared/LS_root/jobs/mme-test-sa/azureml/63511730-a6f0-4a6e-984c-ed972840081f/mounts/energy/energy_train']\n",
      "\n",
      "Script type = None\n",
      "max_horizon: 10\n",
      "target_column: Solar\n",
      "timestamp_column: EndDate\n",
      "group_column_names: ['Suburb', 'Home']\n",
      "grain_column_names: ['Suburb', 'Home']\n",
      "retrain_failed_models: False\n"
     ]
    },
    {
     "ename": "ExperimentExecutionException",
     "evalue": "ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    736\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0;32m--> 737\u001b[0;31m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mget_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \"\"\"\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_run_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipeline_run_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/_aeva_provider.py\u001b[0m in \u001b[0;36mget_status\u001b[0;34m(self, pipeline_run_id, node_id)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \"\"\"\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_caller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_status_code_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_run_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/_restclients/aeva/service_caller.py\u001b[0m in \u001b[0;36mget_node_status_code_async\u001b[0;34m(self, pipeline_run_id, node_id)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mworkspace_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workspace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline_run_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_run_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             custom_headers=self._get_custom_headers())\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/_restclients/aeva/aml_pipelines_api10.py\u001b[0m in \u001b[0;36mapi_v10_subscriptions_by_subscription_id_resource_groups_by_resource_group_name_providers_microsoft_machine_learning_services_workspaces_by_workspace_name_pipeline_runs_by_pipeline_run_id_graph_node_status_code_post\u001b[0;34m(self, subscription_id, resource_group_name, workspace_name, pipeline_run_id, node_id_path, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         response = self._client.send(\n\u001b[0;32m-> 2577\u001b[0;31m             request, header_parameters, body_content, stream=False, **operation_config)\n\u001b[0m\u001b[1;32m   2578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/msrest/service_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, headers, content, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mpipeline_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;31m# There is too much thing that expects this method to return a \"requests.Response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/msrest/pipeline/__init__.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mfirst_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_policies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_policies\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/msrest/pipeline/__init__.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/msrest/pipeline/requests.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/msrest/pipeline/__init__.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/msrest/pipeline/requests.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         )\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/msrest/universal_http/requests.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mrequests_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRequestsHTTPSender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrequests_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/msrest/universal_http/requests.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExperimentExecutionException\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c525ff7b8c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0;32m--> 295\u001b[0;31m                                                              raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    296\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                                 \u001b[0;31m# If there are package conflicts in the user's environment, the run rehydration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    742\u001b[0m                                 \u001b[0;34m\"https://aka.ms/aml-docs-cancel-run\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExperimentExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExperimentExecutionException\u001b[0m: ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succesfully trained, registered Automated ML models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Review outputs of the training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training pipeline will train and register models to the Workspace. You can review trained models in the Azure Machine Learning Studio under 'Models'.\n",
    "If there are any issues with training, you can go to 'many-models-training' run under the pipeline run and explore logs under 'Logs'.\n",
    "You can look at the stdout and stderr output under logs/user/worker/<ip> for more details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Get list of AutoML runs along with registered model names and tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet will iterate through all the automl runs for the experiment and list the details.\n",
    "\n",
    "**Framework** - AutoML, **Dataset** - input data set, **Run** - AutoML run id, **Status** - AutoML run status,  **Model** - Registered model name, **Tags** - Tags for model, **StartTime** - Start time, **EndTime** - End time, **ErrorType** - ErrorType, **ErrorCode** - ErrorCode, **ErrorMessage** - Error Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training output has 50 rows. Please open /mnt/batch/tasks/shared/LS_root/mounts/clusters/julian-ci/code/Users/julianle/Projects/ManyModelsforEnergy/Automated_ML/02_AutoML_Training_Pipeline/training.csv to browse through all the output.\n"
     ]
    }
   ],
   "source": [
    "from scripts.helper import get_training_output\n",
    "import os\n",
    "\n",
    "training_results_name = \"training_results\"\n",
    "\n",
    "training_file = get_training_output(run, training_results_name, training_output_name)\n",
    "all_columns = [\"Framework\", \"Dataset\", \"Run\", \"Status\", \"Model\", \"Tags\", \"StartTime\", \"EndTime\" , \"ErrorType\", \"ErrorCode\", \"ErrorMessage\" ]\n",
    "df = pd.read_csv(training_file, delimiter=\" \", header=None, names=all_columns)\n",
    "training_csv_file = \"training.csv\"\n",
    "df.to_csv(training_csv_file)\n",
    "print(\"Training output has\", df.shape[0], \"rows. Please open\", os.path.abspath(training_csv_file), \"to browse through all the output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Framework</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Run</th>\n",
       "      <th>Status</th>\n",
       "      <th>Model</th>\n",
       "      <th>Tags</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>ErrorType</th>\n",
       "      <th>ErrorCode</th>\n",
       "      <th>ErrorMessage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AutoML</td>\n",
       "      <td>Bondi_home9</td>\n",
       "      <td>AutoML_e8613d15-0355-44f1-a2be-290a396d4bed</td>\n",
       "      <td>Completed</td>\n",
       "      <td>automl_1704596300685ffc01afd572da5a30a03c784c09610095be3bae9f125e8737f3</td>\n",
       "      <td>{'ModelType': 'AutoML', 'Suburb': 'Bondi', 'Home': 'home9', 'InputData': 'Bondi_home9.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': '1704596300685ffc01afd572da5a30a03c784c09610095be3bae9f125e8737f3'}</td>\n",
       "      <td>2020-09-24 06:09:45.449721</td>\n",
       "      <td>2020-09-24 06:21:57.250943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AutoML</td>\n",
       "      <td>NorthBridge_home2</td>\n",
       "      <td>AutoML_9cc87304-7b43-42e5-b719-8394c889bc1c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>automl_b8724c8c56fa9316b3d1fae724774bd51f53f7dc6dde0da0d8a7bee5844b7cd6</td>\n",
       "      <td>{'ModelType': 'AutoML', 'Suburb': 'NorthBridge', 'Home': 'home2', 'InputData': 'NorthBridge_home2.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': 'b8724c8c56fa9316b3d1fae724774bd51f53f7dc6dde0da0d8a7bee5844b7cd6'}</td>\n",
       "      <td>2020-09-24 06:21:58.690233</td>\n",
       "      <td>2020-09-24 06:31:34.942275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AutoML</td>\n",
       "      <td>Bondi_home7</td>\n",
       "      <td>AutoML_60b6eb39-b4c3-4043-98bc-04f17a563257</td>\n",
       "      <td>Completed</td>\n",
       "      <td>automl_fd1179616c935236e39bc13ae5aeecb1383956c61026e1fdc15cf8f0d8bb4e8e</td>\n",
       "      <td>{'ModelType': 'AutoML', 'Suburb': 'Bondi', 'Home': 'home7', 'InputData': 'Bondi_home7.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': 'fd1179616c935236e39bc13ae5aeecb1383956c61026e1fdc15cf8f0d8bb4e8e'}</td>\n",
       "      <td>2020-09-24 06:31:36.732972</td>\n",
       "      <td>2020-09-24 06:40:37.129168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AutoML</td>\n",
       "      <td>AlbertPark_home1</td>\n",
       "      <td>AutoML_eb1328f3-4a33-4304-802b-567e4e53ac3e</td>\n",
       "      <td>Completed</td>\n",
       "      <td>automl_bb3d06532a80b0cea738dd967087fbb6f22a4c013212621349906bdec735a156</td>\n",
       "      <td>{'ModelType': 'AutoML', 'Suburb': 'AlbertPark', 'Home': 'home1', 'InputData': 'AlbertPark_home1.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': 'bb3d06532a80b0cea738dd967087fbb6f22a4c013212621349906bdec735a156'}</td>\n",
       "      <td>2020-09-24 06:09:55.945220</td>\n",
       "      <td>2020-09-24 06:23:35.374225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AutoML</td>\n",
       "      <td>Manly_home6</td>\n",
       "      <td>AutoML_6e6befd2-e4e5-4bca-a7d0-c2b4b167e39c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>automl_055917f29e69e427fdf02837ed27e226382c887b4b6eb53ffd0ae868d0871b93</td>\n",
       "      <td>{'ModelType': 'AutoML', 'Suburb': 'Manly', 'Home': 'home6', 'InputData': 'Manly_home6.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': '055917f29e69e427fdf02837ed27e226382c887b4b6eb53ffd0ae868d0871b93'}</td>\n",
       "      <td>2020-09-24 06:23:37.002372</td>\n",
       "      <td>2020-09-24 06:34:15.474209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Framework            Dataset                                          Run  \\\n",
       "0  AutoML    Bondi_home9        AutoML_e8613d15-0355-44f1-a2be-290a396d4bed   \n",
       "1  AutoML    NorthBridge_home2  AutoML_9cc87304-7b43-42e5-b719-8394c889bc1c   \n",
       "2  AutoML    Bondi_home7        AutoML_60b6eb39-b4c3-4043-98bc-04f17a563257   \n",
       "3  AutoML    AlbertPark_home1   AutoML_eb1328f3-4a33-4304-802b-567e4e53ac3e   \n",
       "4  AutoML    Manly_home6        AutoML_6e6befd2-e4e5-4bca-a7d0-c2b4b167e39c   \n",
       "\n",
       "      Status  \\\n",
       "0  Completed   \n",
       "1  Completed   \n",
       "2  Completed   \n",
       "3  Completed   \n",
       "4  Completed   \n",
       "\n",
       "                                                                     Model  \\\n",
       "0  automl_1704596300685ffc01afd572da5a30a03c784c09610095be3bae9f125e8737f3   \n",
       "1  automl_b8724c8c56fa9316b3d1fae724774bd51f53f7dc6dde0da0d8a7bee5844b7cd6   \n",
       "2  automl_fd1179616c935236e39bc13ae5aeecb1383956c61026e1fdc15cf8f0d8bb4e8e   \n",
       "3  automl_bb3d06532a80b0cea738dd967087fbb6f22a4c013212621349906bdec735a156   \n",
       "4  automl_055917f29e69e427fdf02837ed27e226382c887b4b6eb53ffd0ae868d0871b93   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                        Tags  \\\n",
       "0  {'ModelType': 'AutoML', 'Suburb': 'Bondi', 'Home': 'home9', 'InputData': 'Bondi_home9.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': '1704596300685ffc01afd572da5a30a03c784c09610095be3bae9f125e8737f3'}               \n",
       "1  {'ModelType': 'AutoML', 'Suburb': 'NorthBridge', 'Home': 'home2', 'InputData': 'NorthBridge_home2.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': 'b8724c8c56fa9316b3d1fae724774bd51f53f7dc6dde0da0d8a7bee5844b7cd6'}   \n",
       "2  {'ModelType': 'AutoML', 'Suburb': 'Bondi', 'Home': 'home7', 'InputData': 'Bondi_home7.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': 'fd1179616c935236e39bc13ae5aeecb1383956c61026e1fdc15cf8f0d8bb4e8e'}               \n",
       "3  {'ModelType': 'AutoML', 'Suburb': 'AlbertPark', 'Home': 'home1', 'InputData': 'AlbertPark_home1.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': 'bb3d06532a80b0cea738dd967087fbb6f22a4c013212621349906bdec735a156'}     \n",
       "4  {'ModelType': 'AutoML', 'Suburb': 'Manly', 'Home': 'home6', 'InputData': 'Manly_home6.csv', 'StepRunId': 'ad9d6e9a-de2d-4460-9f6c-6a13c51f033a', 'RunId': '30060a76-710e-4a4c-8b32-366ef11a4f98', 'Hash': '055917f29e69e427fdf02837ed27e226382c887b4b6eb53ffd0ae868d0871b93'}               \n",
       "\n",
       "                    StartTime                     EndTime  ErrorType  \\\n",
       "0  2020-09-24 06:09:45.449721  2020-09-24 06:21:57.250943 NaN          \n",
       "1  2020-09-24 06:21:58.690233  2020-09-24 06:31:34.942275 NaN          \n",
       "2  2020-09-24 06:31:36.732972  2020-09-24 06:40:37.129168 NaN          \n",
       "3  2020-09-24 06:09:55.945220  2020-09-24 06:23:35.374225 NaN          \n",
       "4  2020-09-24 06:23:37.002372  2020-09-24 06:34:15.474209 NaN          \n",
       "\n",
       "   ErrorCode  ErrorMessage  \n",
       "0 NaN        NaN            \n",
       "1 NaN        NaN            \n",
       "2 NaN        NaN            \n",
       "3 NaN        NaN            \n",
       "4 NaN        NaN            "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Publish and schedule the pipeline (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Publish the pipeline\n",
    "\n",
    "Once you have a pipeline you're happy with, you can publish a pipeline so you can call it programmatically later on. See this [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-your-first-pipeline#publish-a-pipeline) for additional information on publishing and calling pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# published_pipeline = pipeline.publish(name = 'automl_train_many_models',\n",
    "#                                      description = 'train many models',\n",
    "#                                      version = '1',\n",
    "#                                      continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Schedule the pipeline\n",
    "You can also [schedule the pipeline](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-schedule-pipelines) to run on a time-based or change-based schedule. This could be used to automatically retrain models every month or based on another trigger such as data drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "    \n",
    "# training_pipeline_id = published_pipeline.id\n",
    "\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1, start_time=\"2020-01-01T09:00:00\")\n",
    "# recurring_schedule = Schedule.create(ws, name=\"automl_training_recurring_schedule\", \n",
    "#                             description=\"Schedule Training Pipeline to run on the first day of every month\",\n",
    "#                             pipeline_id=training_pipeline_id, \n",
    "#                             experiment_name=experiment.name, \n",
    "#                             recurrence=recurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Bookkeeping of workspace (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Cancel any runs that are running\n",
    "\n",
    "To cancel any runs that are still running in a given experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.helper import cancel_runs_in_experiment\n",
    "# failed_experiment =  'Please modify this and enter the experiment name'\n",
    "# # Please note that the following script cancels all the currently running runs in the experiment\n",
    "# cancel_runs_in_experiment(ws, failed_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've trained and scored the models, move on to [03_AutoML_Forecasting_Pipeline.ipynb](../03_AutoML_Forecasting_Pipeline/03_AutoML_Forecasting_Pipeline.ipynb) to make forecasts with your models."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "deeptim"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
